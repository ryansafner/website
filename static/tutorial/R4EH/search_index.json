[
["index.html", "R For Econometrics: A Modest Handbook Introduction How to Read this Guide Other Comments", " R For Econometrics: A Modest Handbook Ryan Safner (safner@hood.edu) Last Updated: 2018-12-18 Introduction This is a guide to using R for basic data analysis used in econometrics, namely OLS regression and its extensions. This guide is merely how to apply basic econometrics knowledge into R commands, that is, it assumes you already understand the concepts. This is not an econometrics textbook, it will not describe the theory and explanation behind various concepts, only a guide of how to model and apply them in R. For more on the theoretical background, see the lecture slides in my Econometrics class. How to Read this Guide As an econometrics student, the core of your data analysis life will be working with data.frames (think “spreadsheets”, where each row is an observation and each column is a variable). You will: import data into a data.frame transform (“wrangle”) data into more useful variables or data.frames plot data from data.frames (in histograms, scatterplots, etc.) run regressions using data from data.frames This guide attempts to introduce you to R from the ground up, which means it starts with simpler types of objects than data.frames (namely, vectors). I would not necessarily recommend reading from beginning to end. The first two sections describe a lot about R as a language and discuss different types of R objects, data types, and commands. Starting at the very beginning, reading them will seem overwhelming. They will become more useful to return to for reference later, once you have some practice under your belt. Other Comments Open Source: The raw (.Rmd) code used to produce this guide, along with the guide itself, are available on GitHub, and are updated regularly. GitHub does not automatically render HTML, so download the HTML file and open it, or view it where I host it on my website. Note to Students: This is a work in progress, check the date at the top for when this was last updated. This compiles all of my instructions, advice, and examples from econometrics class lectures regarding R. It also contains some advanced material that I did not or will not cover in class, but will be useful to know for future data analysis and understanding or diagnosing problems. Note to Everyone Else: This guide is oriented primarily for my Econometrics class at Hood College, but should be of wider use to anyone interest ed in learning R for data analysis. Lecture slides, handouts, and guides (both PDFs and source code in R Markdown) are openly available on GitHub. See also my companion guide to using R Markdown to more effectively manage your entire workflow (text, data analysis, tables, graphs, and citations!) in a single plain text file and make your work reproducible and shareable, hosted on my website, with source available on GitHub "],
["basics.html", "Chapter 1 Basics 1.1 Operating R Studio 1.2 Working Directory (wd) 1.3 Packages 1.4 Useful Packages 1.5 Calculations 1.6 Hints for Writing Code 1.7 Getting Help", " Chapter 1 Basics 1.1 Operating R Studio There are a few ways you can use R Studio: Command line/Console: writing each command by itself and copying down the result as needed Great for testing individual commands to see what happens Not reproducible! Not saved! NOT RECOMMENDED! .R files: A sequence of commands (and hopefully comments) saved as a script, the entire script is run all at once Can test individual commands in command line and then put good commands in .R file Equivalent to a .do file for Stata Reproducible, saved, commented R Markdown (.Rmd) files: A plain text document written in R Markdown language Allows for individual chunks of R code to be run individually (great for testing one command instead of all at once) Reproducible, saved, commented as if a normal document Can write an entire document (text, equations, R commands, figures, tables, etc) with one file! Can export to html, MS Word, Beamer, etc! Markdown is a language that is intuitive, simple, human- and machine-readable Rstudio Windows 1.1.1 Keyboard Shortcuts Ctrl+2: move cursor to console Ctrl (Cmd on Mac)+Enter: run current line (from editor) in console Ctrl (Cmd on Mac)+Enter Uparrow: retrieve recent commands in console Ctrl (Cmd on Mac)+Uparrow: search previous commands Option -: insert assignment operator (&lt;-) Ctrl (Cmd on Mac)+Shift+M: insert pipe operator (%&gt;%) 1.2 Working Directory (wd) R assumes a default (often inconvenient) working directory on your computer this is where it thinks it will load any files you want to load and save anything you want to save by default Find out where R currently thinks this is with getwd() this is often Operating System specific, e.g.: Mac: /Users/yourusername/ Windows: C:/Users/yourusername/Documents/ you can move everything you want to load into this folder on your computer (and save everything there too), but this may be inconvenient Change the working directory to wherever you plan on keeping your related data and documents with setwd(&quot;/path/to/folder&quot;) you can move to a new wd relative to the current working directory: move down a folder by typing the folder name with a / after i e.g. to move from /Ryansafner/Documents/ to /Ryansafner/Documents/Econometrics/ move up one folder in a hierarchy with .. e.g. to move from /Ryansafner/Documents/ to /Ryansafner/Downloads, use setwd(&quot;../Downloads/&quot;) to move up from the Documents folder to Ryansafner folder, then down to Downloads 1.3 Packages Packages are extensions of base R designed by users Remember, R is open source, packages are usually published first on Github Official packages distributed and documented through CRAN To use a (previously-installed) package (note the “”), use the library() command: library(&quot;packagename&quot;) If you do not have a package, they are easy to install with (note the plural “s”) install.packages(&quot;packagename&quot;) To install or load multiple packages at once, we can use the c() function to select multiple packages (see below) library(c(&quot;gapminder&quot;,&quot;ggplot2&quot;,&quot;dplyr&quot;)) 1.4 Useful Packages There are several packages we will use often (and are featured later in this guide) Packages are often very well-documented with explanations and examples Google each package for more information 1.5 Calculations R can be used as a calculator Basic operations +, -, *, / More advanced math operators like exponents, logarithms, trigonometric functions, etc 2+2 ## [1] 4 6^2 # 6 to the second power (i.e. squared) ## [1] 36 sqrt(100/4) # square root ## [1] 5 log(5) # logarithm ## [1] 1.609438 sin(2*pi) # sin ## [1] -2.449294e-16 factorial(5) # factorial (e.g. 5!) ## [1] 120 choose(2,6) # binomial choose function ## [1] 0 # order of operations matters 3*3+4 ## [1] 13 3*(3+4) ## [1] 21 Note on Notation: R often reports very large (or very small) numbers in scientific notation with e For positive e: the number of zeros (or digits after the decimal point) to the right of a number e.g. \\(1.25e6 = 1.25 \\times 10^6 = 1,250,000\\) For negative e: one less than the number of zeros (or digits after the decimal point) to the left of a number e.g. \\(1.25e-6 = 1.25 \\times 10^{-6} = 0.00000125\\) 1.6 Hints for Writing Code 1.6.1 Naming Objects Object names cannot start with a digit or contain a space or comma FOR THE LOVE OF GOD AVOID SPACES IN GENERAL You’ve seen webpages intended to be called &quot;my webpage in html&quot; turned into http://my%20webpage%20in%20html.html Consider both your R objects and your files and folder names on your computer…(/School/ECON_480_Econometrics/Homeworks_and_Data/) It will be wise to adopt some consistent standard for demarcating names: i.use.snake.case otherPeopleUseCamelCase some_people_use_underscores And_aFew.People_RENOUNCEconvention 1.6.2 Commenting Always comment your commands! Describe what you are doing so someone else (or you, 5 years later) can understand what is happening and why! Use the hashtag # to start a comment (R ignores everything on that line after the hashtag) Can be made its own line or at the end of lines e.g. # Run regression of y on x, save as reg1 reg1&lt;-lm(y~x, data=mydata) # runs regression using mydata summary(reg1$coefficients) # prints coefficients 1.6.3 Managing Your Workflow Save often! Better yet, ask me about version control and GitHub 1.7 Getting Help You can get documentation, explanations, and examples of every command in R simply type ?commandname or help(&quot;commandname&quot;) Meet your new friend: Meet your new best friend: The only way to learn coding is by tweaking existing examples, messing up, and searching the internet for help! "],
["r-objects.html", "Chapter 2 R Objects 2.1 Vectors 2.2 Other Object Types 2.3 Data Classes 2.4 Checking or Reclassifying Objects", " Chapter 2 R Objects R is an object-oriented programming language, meaning we will almost always store data in objects and run functions on those objects. We assign values to objects using the assignment operator (&lt;-)1 myobject&lt;-value The keyboard shortcut for inserting &lt;- (inside the Console or an R chunk) is Alt+- (on Windows) or Option+- (on Mac). Functions take the form: functionname(myobject) Functions can have other functions for arguments (the object the function is run on), e.g. round(rnorm(5),2) # rnorm(5) takes 5 random draws from a normal distribution # then round(, 2) rounds the result to 2 decimal places 2.1 Vectors The simplest data structure in R is a vector, simply a collection of objects or elements. To construct a vector, use the “combine/concatenate” function “c()” As an example, let’s make a vector of the numbers 1 through 5, called v. v&lt;-c(1,2,3,4,5) We can also build vectors via generating mathematical series with the : operator, which lists all integers in a series from beginning:end. v&lt;-1:5 To inspect an object, we simply “call” it up by typing the name of the object to print its contents. v ## [1] 1 2 3 4 5 2.1.1 Functions Since a vector is an object, we can run functions on that object. Let’s start with some simple mathematical functions, such as taking the sum and taking the mean of our simple vector v. sum(v) ## [1] 15 mean(v) ## [1] 3 Functions in R are “vectorized,” meaning the function is run on every object inside a vector. We can perform mathematical operations on a vector as a whole: sum(1:5) ## [1] 15 mean(1:5) ## [1] 3 2.2 Other Object Types 2.2.1 Lists A list is a non-atomic vector, meaning you can gather data elements of different classes in one object mylist&lt;-list(5, pi, TRUE, 4.3, &quot;cabbage&quot;) class(mylist) ## [1] &quot;list&quot; Another great property of lists is that elements of the list can themselves be vectors vectored.list&lt;-list(c(1.82, 1940, 93.20, 192.917), c(&quot;Orange&quot;, &quot;Cyan&quot;, &quot;Pink&quot;), c(TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE)) str(vectored.list) # look at structure of the list ## List of 3 ## $ : num [1:4] 1.82 1940 93.2 192.92 ## $ : chr [1:3] &quot;Orange&quot; &quot;Cyan&quot; &quot;Pink&quot; ## $ : logi [1:8] TRUE FALSE TRUE TRUE FALSE TRUE ... We can create a label for each element in a list, called a name vectored.list&lt;-list(numbers=c(1.82, 1940, 93.20, 192.917), # first element is a vector called &#39;numbers&#39; colors=c(&quot;Orange&quot;, &quot;Cyan&quot;, &quot;Pink&quot;), # second element is a vector called `colors` logic=c(TRUE, FALSE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE)) # third element is a vector called `logic` vectored.list ## $numbers ## [1] 1.820 1940.000 93.200 192.917 ## ## $colors ## [1] &quot;Orange&quot; &quot;Cyan&quot; &quot;Pink&quot; ## ## $logic ## [1] TRUE FALSE TRUE TRUE FALSE TRUE FALSE FALSE The names command prints (or changes) the name of the label of each element in the list names(vectored.list) # print the names of the list elements ## [1] &quot;numbers&quot; &quot;colors&quot; &quot;logic&quot; names(vectored.list)&lt;-c(&quot;name1&quot;,&quot;name2&quot;,&quot;name3&quot;) # rename the lables to &#39;name1&#39;, &#39;name2&#39;, and &#39;name3&#39; names(vectored.list) # print new names ## [1] &quot;name1&quot; &quot;name2&quot; &quot;name3&quot; vectored.list # print list with new names ## $name1 ## [1] 1.820 1940.000 93.200 192.917 ## ## $name2 ## [1] &quot;Orange&quot; &quot;Cyan&quot; &quot;Pink&quot; ## ## $name3 ## [1] TRUE FALSE TRUE TRUE FALSE TRUE FALSE FALSE 2.2.2 Matrix Everything thus far has been 1 dimension, but we often work with 2-dimensional data Rows are observations Columns are variables A matrix matrix() command creates a matrix by column, can define number of rows with nrow=, R will divide the elements into equal number of columns matrix1&lt;-matrix(c(1,2,3,4,5,6),nrow=3) # make a 3-row matrix matrix1 ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 2.2.3 Data Frame The most important object in R is a data frame (what you call a “spreadsheet”), used for statistics, plots, regressions, etc “Rectangular” data, rows are observations, columns are variables Can hold variables of different classes (e.g. a quantitative variable like income, a character variable like name, etc) In essence, data frames are actually lists (where each list object itself is a vector) All vectors (columns) must have the same length! df&lt;-data.frame(x = 1:3, y = c(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;), z = c(TRUE, FALSE, TRUE)) df ## x y z ## 1 1 a TRUE ## 2 2 b FALSE ## 3 3 c TRUE 2.3 Data Classes Vectors must contain the same type of elements (e.g. numerical or text) Technically this refers to atomic vectors (nearly all vectors are atomic) Vectors with “mixed” types will convert all elements to the lowest-common denominator, e.g. character You can always check the type of vector using class() mixed&lt;-c(5, pi, TRUE, 4.3, &quot;cabbage&quot;) class(mixed) ## [1] &quot;character&quot; 2.3.1 Numeric Numeric (aka “double”), as it sounds, can perform mathematical operations numeric&lt;-c(1,2,3,4,5) There are two types of numeric objects: double and integer 2.3.2 Double If numeric values contain decimal points, they are technically called floating point double or simply double class R may simply call them numeric, but contrast with integer below double&lt;-c(pi,2.34,9.99) class(double) ## [1] &quot;numeric&quot; typeof(double) # will return the more specific type ## [1] &quot;double&quot; is.double(double) # a logical test to see if object is &quot;double&quot; type ## [1] TRUE is.integer(double) # a logical test to see if object is &quot;integer&quot; type ## [1] FALSE 2.3.2.1 Integer If numeric values are all whole numbers, they are integer class integers&lt;-c(1,2,3,4) class(integers) ## [1] &quot;numeric&quot; typeof(integers) ## [1] &quot;double&quot; is.double(double) ## [1] TRUE is.integer(double) ## [1] FALSE 2.3.3 Logical Logical is a series of binary elements or statements that can either be TRUE or FALSE logical&lt;-c(TRUE,FALSE,FALSE,TRUE) We can perform logical tests with common operators: &lt; less than &gt; greater than &lt;= less than or equal to (\\(\\leq\\)) &gt;= greater than or equal to (\\(\\geq\\)) == is equal to (note two equals signs are needed!) != is not equal to %in% is a member of a set (\\(\\in\\)) 3==4 #is 3 equal to 4? ## [1] FALSE 3&lt;4 # is three less than 4? ## [1] TRUE 3&lt;=4 # is three less than or equal to 4? ## [1] TRUE 3&gt;4 # is three greater than 4? ## [1] FALSE 3!=4 # is three not equal to four? ## [1] TRUE 3 %in% c(0,1,2) # is three in the following set of numbers? ## [1] FALSE 3 %in% c(0,1,2,3) # is three in the following set of numbers? ## [1] TRUE We are not limited to using numeric data, R can also perform logical tests on other classes of variable, like characters (which need quotes): &quot;red&quot;==&quot;blue&quot; # is red the same as blue? ## [1] FALSE &quot;red&quot;!=&quot;blue&quot; # is red not equal to blue? ## [1] TRUE political.party&lt;-c(&quot;Republican&quot;,&quot;Democrat&quot;) # define political party as a set of Republican and Democrat &quot;Libertarian&quot; %in% political.party # check if Libertarian is in the set of political parties we created ## [1] FALSE &quot;Democrat&quot; %in% political.party # check if Democrat is in our set of political parties ## [1] TRUE We can also perform more than one test at a time with multiple conditions: &amp; AND | OR 2==2 &amp; 2&gt;3 # is 2 equal to 2 AND greater than 3? ## [1] FALSE 2==2 | 2&gt;3 # is 2 equal to 2 OR greater than 3? ## [1] TRUE These commands will become very useful when we want to subset data or look at portions of our data based on some condition 2.3.4 Character Character is a string of text: letters, numbers, and symbols, cannot perform mathematical operations Character values require quotation marks around each value character&lt;-c(&quot;one&quot;,&quot;two&quot;,&quot;7&quot;,&quot;orange&quot;) 2.3.4.1 Dates Dates are a specific type of character class Specific dates Can do days, weeks, months, quarters, years today&lt;-Sys.Date() #print today&#39;s date format(today, format=&quot;%B %d %Y&quot;) # specify how to report date format ## [1] &quot;December 18 2018&quot; months&lt;-seq(as.Date(&quot;2010/1/1&quot;), as.Date(&quot;2012/1/1&quot;), &quot;months&quot;) # generate sequence of months between Jan 2010 and Jan 2012 months ## [1] &quot;2010-01-01&quot; &quot;2010-02-01&quot; &quot;2010-03-01&quot; &quot;2010-04-01&quot; &quot;2010-05-01&quot; ## [6] &quot;2010-06-01&quot; &quot;2010-07-01&quot; &quot;2010-08-01&quot; &quot;2010-09-01&quot; &quot;2010-10-01&quot; ## [11] &quot;2010-11-01&quot; &quot;2010-12-01&quot; &quot;2011-01-01&quot; &quot;2011-02-01&quot; &quot;2011-03-01&quot; ## [16] &quot;2011-04-01&quot; &quot;2011-05-01&quot; &quot;2011-06-01&quot; &quot;2011-07-01&quot; &quot;2011-08-01&quot; ## [21] &quot;2011-09-01&quot; &quot;2011-10-01&quot; &quot;2011-11-01&quot; &quot;2011-12-01&quot; &quot;2012-01-01&quot; 2.3.5 Factor Factor is a special type of character variable, often used to indicate membership in one of several possible categories, called levels (e.g. for plotting, or conditional statistics and data work) students&lt;-factor(c(&quot;freshman&quot;, &quot;senior&quot;, &quot;senior&quot;, &quot;junior&quot;, &quot;freshman&quot;, &quot;sophomore&quot;, &quot;freshman&quot;)) students # note order is arbitrary ## [1] freshman senior senior junior freshman sophomore freshman ## Levels: freshman junior senior sophomore levels(students) #extract unique levels ## [1] &quot;freshman&quot; &quot;junior&quot; &quot;senior&quot; &quot;sophomore&quot; nlevels(students) #count the number of levels ## [1] 4 table(students) #tabulate number of values for each level ## students ## freshman junior senior sophomore ## 3 1 2 1 2.3.5.1 Ordered Factors Factors have ordered levels() which control the order on plots and in table() students.o&lt;-ordered(students, levels=c(&quot;freshman&quot;,&quot;sophomore&quot;,&quot;junior&quot;,&quot;senior&quot;)) students.o ## [1] freshman senior senior junior freshman sophomore freshman ## Levels: freshman &lt; sophomore &lt; junior &lt; senior Be advised: when R stores and calls factors, it actually stores them as integers [1..k, for k categories] instead of characters (e.g. “freshman”=1, “sophomore”=2), making this a nominal variable. This allows for some mathematical operations. An ordered factor is where the ordering matters (e.g. “small”, “medium”, “large” coded as 1, 2, 3 in order) 2.4 Checking or Reclassifying Objects We can always check the class of an object with class() or typeof(). We can perform logical tests is.numeric(), is.factor(), etc. to see if an object is a specified type We can change the class of an object by redefining it with as.classname(), e.g. x&lt;-1:5 is.numeric(x) # check if x is numeric ## [1] TRUE is.factor(x) # check if x is a character ## [1] FALSE x&lt;-as.character(x) # change vector x to a character class(x) ## [1] &quot;character&quot; x&lt;-as.numeric(x) # change vector x back to numeric class(x) ## [1] &quot;numeric&quot; Think of the assignment operator like like an \\(=\\) sign, but we want to avoid using the equals sign. &lt;- was originally its own key on early computer keyboards.↩ "],
["data-wrangling.html", "Chapter 3 Data Wrangling 3.1 Packages 3.2 Importing Data 3.3 Merging Data 3.4 Using the %&gt;% “Pipe” Operator 3.5 Subsetting", " Chapter 3 Data Wrangling Major Work in Progress 90% of data work is “wrangling” raw data files into something we can actually work with There are perhaps 5 common tasks that most data analysis will require some combination of: 1. Importing data (from an external source) 2. Merging data (from multiple sources) 3. Tidying data (transforming it to a useful structure) 4. Subsetting data (for conditional analysis) 5. Summarizing data (in summary statistics and plots) 3.1 Packages All of the tasks in this section can be undertaken with base R commands. However, several packages make these tasks much more efficient and intuitive to understand and document. - dplyr - tidyr - readr 3.2 Importing Data getwd() setwd() list.files() list.dirs() 3.3 Merging Data A simple merge 3.4 Using the %&gt;% “Pipe” Operator 3.5 Subsetting "],
["plotting.html", "Chapter 4 Plotting 4.1 Plotting in Base R 4.2 With ggplot2", " Chapter 4 Plotting Data visualization is one of the most useful tools and gives you the most “bang for your buck.” Base R is very powerful and intuitive to plot, but is not very aesthetically pleasing or advanced. We also use the ggplot2 package, part of the tidyverse to suit our advanced plotting needs. 4.1 Plotting in Base R The basic syntax is quite simple, put the variable(s) you wish to plot (which come from a dataframe) inside the argument of a plot function: plottype(my_df$my_variable1, my_df$my_variable2) If you are using multiple variables, you can avoid having to invoke the same dataframe and $ multiple times by just including the names of the variables in the dataframe, and then add , data=my_df as the final argument of the function, e.g. plottype(my_variable1, my_variable_2, data=my_df) The three simple plots that we can look at are Function Plot Type When Used hist() Histogram Exploring the distribution of a single variable barplot() Bar Graph Exploring the counts of different categories of a variable boxplot() Boxplot Exploring the distribution of a single variable plot() Scatterplot Exploring the relationship between two variables 4.1.1 Histogram library(&quot;gapminder&quot;) hist(gapminder$gdpPercap) 4.1.2 Boxplot Boxplots are similar syntax boxplot(gapminder$gdpPercap) If we want a boxplot for each category, use variable.name~category.variable.name to tell R to plot a boxplot by category boxplot(gdpPercap~continent,data=gapminder) 4.1.3 Scatterplot Scatterplot syntax for plotting is similar to hist() and boxplot(): plot(df$x,df$y) plot(gapminder$gdpPercap, gapminder$lifeExp) 4.2 With ggplot2 `ggplot2 is one of the premier packages at the center of the tidyverse. It is very powerful and creates beautiful data visualizations, but has a steeper learning curve at first. All of those “cool graphics” you see in media outlets such as the New York Times, fivethirtyeight, Vox, the Economist, etc use something are based off of ggplot2. The gg stands for a “grammar of graphics” 4.2.1 Two Ways to Plot Just the single ggplot command Will view plot right after producing it Does not save as an object Need to rerun or copy/paste full command producing plot in order to modify or view it again Can still put it in a document ggplot(...) # make and view plot ggplot(some.options) # remake plot with new options and view plot 4.2.2 Two Ways to Plot II Create an object (as usual in R) This allows you to save the plot for later (re)use Also allows you to modify it Any time you want to view display it (i.e. for putting it in a document), just call up the plot by name plot.name&lt;-ggplot(...) # make plot plot.name&lt;-plot.name+some.options # add new options to existing plot plot.name # view plot plot.name&lt;-ggplot(data=mydf, mapping=aes(x=xvar,y=yvar))+ geom_something(options)+ moreoptions... gg “grammar of graphics” implies any graphic can be built from the same components/layers: Data: base-layer describes the data used mydf is the dataframe containing xvar and yvar aes() “aesthetics” identifies xvar (and if applicable yvar) from data to be “mapped” to a visual mark Geoms: visual marks that represent data observations or models, common examples: e.g. geom_point, geom_line, geom_bar, geom_histogram, geom_density, geom_boxplot Coordinates: Cartesian coordinates are default change scales, axes, labels, etc; advanced options like maps Most important idea to master is aes() aesthetics that map data to visual markings Aesthetics come in many forms and many options, depending on the context of the data Must identify position (e.g. what is x and y) Determine the marking with various geoms (points, bars, lines, boxes, etc) Can pass additional options into geom (color, size, shape, etc) Particularly important if we want color, size, or shape to depend on a particular variable in dataset For our example, we’ll use the mpg dataset loaded with the ggplot2 package library(&quot;ggplot2&quot;) #load ggplot2 mpg #look at dataset ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l… f 18 29 p ## 2 audi a4 1.8 1999 4 manual… f 21 29 p ## 3 audi a4 2 2008 4 manual… f 20 31 p ## 4 audi a4 2 2008 4 auto(a… f 21 30 p ## 5 audi a4 2.8 1999 6 auto(l… f 16 26 p ## 6 audi a4 2.8 1999 6 manual… f 18 26 p ## 7 audi a4 3.1 2008 6 auto(a… f 18 27 p ## 8 audi a4 quat… 1.8 1999 4 manual… 4 18 26 p ## 9 audi a4 quat… 1.8 1999 4 auto(l… 4 16 25 p ## 10 audi a4 quat… 2 2008 4 manual… 4 20 28 p ## # ... with 224 more rows, and 1 more variable: class &lt;chr&gt; Start with the base layer: establish the data source, define \\(x\\) variable mpg.h&lt;-ggplot(data=mpg,mapping=aes(x=hwy)) mpg.h Add a histogram geom_ layer of hwy mpg.h1&lt;-mpg.h+geom_histogram() mpg.h1 Customize the histogram geom_ layer (# of bins, color, etc) mpg.h2&lt;-mpg.h+geom_histogram(bins=20, color=&quot;black&quot;,fill=&quot;indianred&quot;) mpg.h2 Adding additional geom_ layers Add a vertical line for the mean with another geom called vline mpg.h2&lt;-mpg.h2+ geom_vline(xintercept=mean(mpg$hwy),linetype=&quot;dotted&quot;,color=&quot;blue&quot;,size=1) mpg.h2 Editing Coordinates (Axes) Change the labels on the axes with xlab() and ylab() mpg.h2&lt;-mpg.h2+xlab(&quot;Miles Per Gallon (on Highway)&quot;)+ylab(&quot;Number of Cars&quot;) mpg.h2 Other Geoms How about a density plot: use geom_density() instead of geom_histogram() mpg.d&lt;-ggplot(data=mpg,aes(x=hwy))+ geom_density(fill=&quot;indianred&quot;) mpg.d Let’s make a separate density plot for each class, set aes to fill by class mpg.d&lt;-ggplot(data=mpg,aes(x=hwy,fill=class))+ geom_density(alpha=0.5) # alpha adds transparency mpg.d Instead of a density plot, a boxplot by class (note now x is class and y is hwy): mpg.b&lt;-ggplot(data=mpg,aes(x=class,y=hwy,fill=class))+ geom_boxplot() mpg.b Start with the base layer: establish data source, define \\(x\\) and \\(y\\) variables mpg.p&lt;-ggplot(data=mpg,aes(x=displ, y=hwy)) #use mtcars df, let x=displ, y=hwy mpg.p mpg.p&lt;-mpg.p+geom_point() # specify observations as points on graph mpg.p mpg.p&lt;-mpg.p+geom_point(aes(color=manufacturer)) # color data points by manuf. mpg.p mpg.p&lt;-mpg.p+geom_smooth(method=&quot;lm&quot;, color=&quot;black&quot;) # add a black OLS line mpg.p mpg.p&lt;-mpg.p+xlab(&quot;Engine Displacement (Liters)&quot;)+ ylab(&quot;Miles Per Gallon on Highway&quot;) mpg.p Let’s have some fun changing the theme library(&quot;ggthemes&quot;) # need ggthemes package (install if first use) mpg.p&lt;-mpg.p+theme_economist_white() #make it look like The Economist magazine mpg.p mpg.p&lt;-mpg.p+theme_fivethirtyeight() #make it look like fivethirtyeight mpg.p # make columns of separate &#39;facet&#39; figures for each class of car mpg.p&lt;-mpg.p+facet_grid(cols = vars(class)) # make &#39;columns&#39; by variable &#39;class&#39; mpg.p ggplot(data=mpg,aes(x=displ, y=hwy))+geom_point(aes(color=manufacturer))+ geom_smooth(color=&quot;black&quot;,method=&quot;lm&quot;)+ xlab(&quot;Engine Displacement (Liters)&quot;)+ylab(&quot;Miles Per Gallon on Highway&quot;)+ theme_fivethirtyeight()+facet_grid(cols = vars(class)) "],
["regression-basics.html", "Chapter 5 Regression Basics 5.1 Ordinary Least Squares (OLS) Regression 5.2 Prediction 5.3 Residual Plots 5.4 Regression Output Table", " Chapter 5 Regression Basics 5.1 Ordinary Least Squares (OLS) Regression In R, the Ordinary Least Squares (OLS) regression model is simply called the “linear model”, abbreviated lm. Regressions are run on several variables from a data.frame and stored as a lm object that we can inspect and modify. set.seed=1 #makes &#39;random&#39; draws reproducible x&lt;-runif(500,min=0,max=10) #500 draws from uniform distr y&lt;-2*x+rnorm(500,2,4) my_df&lt;-data.frame(x,y) ggplot(my_df, aes(x=x,y=y))+ geom_point(alpha=0.5)+ geom_smooth(method=&quot;lm&quot;, color=&quot;green&quot;)+ xlim(c(0,10))+theme_light() The syntax for running a regression in R is simple. We store the regression as an lm() object (e.g. called “my_reg”) and regress our dependent (mydf$y) variable on (~) the independent (my_df$x) variable. my_reg&lt;-lm(df$y~df$x) Alternatively, we can simply use the variable names from my_df and then tell R that the variables are coming from my_df: my_reg&lt;-lm(y~x, data = my_df) \\[y=\\beta_0+\\beta_1 x\\] When we inspect our lm object, R simply prints the coefficients (“Intercept” for \\(\\hat{\\beta_0}\\)) and (“x” for \\(\\hat{\\beta_1}\\) on \\(x\\)): my_reg ## ## Call: ## lm(formula = y ~ x, data = my_df) ## ## Coefficients: ## (Intercept) x ## 2.406 1.940 We can get a more detailed summary by running summary() on our lm object. summary(my_reg) ## ## Call: ## lm(formula = y ~ x, data = my_df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.2066 -2.7964 -0.1464 2.8866 13.6379 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.4062 0.3687 6.525 1.67e-10 *** ## x 1.9403 0.0657 29.532 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.152 on 498 degrees of freedom ## Multiple R-squared: 0.6365, Adjusted R-squared: 0.6358 ## F-statistic: 872.1 on 1 and 498 DF, p-value: &lt; 2.2e-16 The summary() prints: The formula for the regression A 5 number summary of the distribution of the residuals Table of coefficients Column 1: Estimate for each \\(\\beta\\) Column 2: Standard error of each \\(\\beta\\) Column 3: \\(t\\)-statistic for each \\(\\beta\\) with \\(H_0: \\, \\beta=0\\) Column 4: \\(p\\)-value for the \\(t\\)-test Regression Diagnostics Standard error of the regression (SER), R calls it Residual standard error (RSE) R-squared and Adjusted R-squared “All \\(F\\)-test” where \\(H_0: \\text{ all } \\beta\\text{&#39;s}=0\\) Inside the lm object my_reg is stored a lot of things that may not show up in the summary. To get a full inspection, check the structure with str(). str(my_reg) ## List of 12 ## $ coefficients : Named num [1:2] 2.41 1.94 ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;(Intercept)&quot; &quot;x&quot; ## $ residuals : Named num [1:500] 5.63 1.25 -1.36 7 -2.46 ... ## ..- attr(*, &quot;names&quot;)= chr [1:500] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ effects : Named num [1:500] -264.17 122.62 -1.58 6.8 -2.63 ... ## ..- attr(*, &quot;names&quot;)= chr [1:500] &quot;(Intercept)&quot; &quot;x&quot; &quot;&quot; &quot;&quot; ... ## $ rank : int 2 ## $ fitted.values: Named num [1:500] 9.15 8.03 13.4 17.47 20.97 ... ## ..- attr(*, &quot;names&quot;)= chr [1:500] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ assign : int [1:2] 0 1 ## $ qr :List of 5 ## ..$ qr : num [1:500, 1:2] -22.3607 0.0447 0.0447 0.0447 0.0447 ... ## .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. ..$ : chr [1:500] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## .. .. ..$ : chr [1:2] &quot;(Intercept)&quot; &quot;x&quot; ## .. ..- attr(*, &quot;assign&quot;)= int [1:2] 0 1 ## ..$ qraux: num [1:2] 1.04 1.03 ## ..$ pivot: int [1:2] 1 2 ## ..$ tol : num 1e-07 ## ..$ rank : int 2 ## ..- attr(*, &quot;class&quot;)= chr &quot;qr&quot; ## $ df.residual : int 498 ## $ xlevels : Named list() ## $ call : language lm(formula = y ~ x, data = my_df) ## $ terms :Classes &#39;terms&#39;, &#39;formula&#39; language y ~ x ## .. ..- attr(*, &quot;variables&quot;)= language list(y, x) ## .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. ..$ : chr [1:2] &quot;y&quot; &quot;x&quot; ## .. .. .. ..$ : chr &quot;x&quot; ## .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;x&quot; ## .. ..- attr(*, &quot;order&quot;)= int 1 ## .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. ..- attr(*, &quot;response&quot;)= int 1 ## .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. ..- attr(*, &quot;predvars&quot;)= language list(y, x) ## .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;y&quot; &quot;x&quot; ## $ model :&#39;data.frame&#39;: 500 obs. of 2 variables: ## ..$ y: num [1:500] 14.78 9.28 12.04 24.47 18.51 ... ## ..$ x: num [1:500] 3.47 2.9 5.67 7.76 9.57 ... ## ..- attr(*, &quot;terms&quot;)=Classes &#39;terms&#39;, &#39;formula&#39; language y ~ x ## .. .. ..- attr(*, &quot;variables&quot;)= language list(y, x) ## .. .. ..- attr(*, &quot;factors&quot;)= int [1:2, 1] 0 1 ## .. .. .. ..- attr(*, &quot;dimnames&quot;)=List of 2 ## .. .. .. .. ..$ : chr [1:2] &quot;y&quot; &quot;x&quot; ## .. .. .. .. ..$ : chr &quot;x&quot; ## .. .. ..- attr(*, &quot;term.labels&quot;)= chr &quot;x&quot; ## .. .. ..- attr(*, &quot;order&quot;)= int 1 ## .. .. ..- attr(*, &quot;intercept&quot;)= int 1 ## .. .. ..- attr(*, &quot;response&quot;)= int 1 ## .. .. ..- attr(*, &quot;.Environment&quot;)=&lt;environment: R_GlobalEnv&gt; ## .. .. ..- attr(*, &quot;predvars&quot;)= language list(y, x) ## .. .. ..- attr(*, &quot;dataClasses&quot;)= Named chr [1:2] &quot;numeric&quot; &quot;numeric&quot; ## .. .. .. ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;y&quot; &quot;x&quot; ## - attr(*, &quot;class&quot;)= chr &quot;lm&quot; Note that lm objects are actually lists, (data.frames are also lists), so we can extract elements of the list and subset using $ or [[]]. Some of the important elements of the list: my_reg$coefficients is a list of coefficients my_reg$residuals is a list comprised of the residual for each x value my_reg$fitted.values is a list comprised of the predicted/fitted value (\\(\\hat{y}\\)) for each x value my_reg$coefficients # look at coefficients ## (Intercept) x ## 2.406214 1.940304 my_reg$residuals[1:5] # look at first 5 residuals ## 1 2 3 4 5 ## 5.627585 1.246638 -1.355966 6.995149 -2.459027 my_reg$fitted.values[1:5] # look at first 5 fitted.values ## 1 2 3 4 5 ## 9.147826 8.034352 13.398553 17.470953 20.966092 These stored values will come in handy. We can run functions on them, for example, to discover things about the residuals: summary(my_reg$residuals) # the same as the first thing printed in the regression output above! ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -13.2066 -2.7964 -0.1464 0.0000 2.8866 13.6379 sd(my_reg$residuals) # the standard deviation of the residuals ## [1] 4.147971 Since these are stored in lm as objects, we can also assign them to new columns in our original data.frame, my_df. This can be helpful for plotting with x, y, the residuals \\(\\epsilon\\), and the predicted values \\(\\hat{y}\\). # save predicted values from model as &quot;yhat&quot; my_df$yhat&lt;-my_reg$fitted.values # save residuals from model as &quot;res&quot; my_df$res&lt;-my_reg$residuals # look at new dataframe kable(head(my_df)) x y yhat res 3.474513 14.77541 9.147826 5.627585 2.900647 9.28099 8.034352 1.246638 5.665265 12.04259 13.398553 -1.355966 7.764111 24.46610 17.470952 6.995149 9.565446 18.50706 20.966092 -2.459027 6.324263 13.18435 14.677210 -1.492858 There are also specific functions for assigning the predicted values and the residuals to a data.frame, using the lm object as the argument. They will produce the same result as above. # save predicted values from model as &quot;yhat&quot; my_df$yhat&lt;-predict(my_reg) # save residuals from model as &quot;res&quot; my_df$res&lt;-residuals(my_reg) # we get the same result head(my_df) ## x y yhat res ## 1 3.474513 14.77541 9.147826 5.627585 ## 2 2.900647 9.28099 8.034352 1.246638 ## 3 5.665265 12.04259 13.398553 -1.355966 ## 4 7.764111 24.46610 17.470953 6.995149 ## 5 9.565446 18.50706 20.966092 -2.459027 ## 6 6.324263 13.18435 14.677210 -1.492858 5.1.1 Diagnostics Some of the regression diagnostics are stored (idiosyncratically) in the summary() object, and can be extracted by name: summary(my_reg)$sigma # extract residual squared error (SER) ## [1] 4.152134 summary(my_reg)$r.squared # extract R^2 ## [1] 0.6365256 summary(my_reg)$adj.r.squared # extract adjusted R^2 ## [1] 0.6357957 summary(my_reg)$f # extract the F-statistic ## value numdf dendf ## 872.1101 1.0000 498.0000 These might be useful if we wished to perform manual calculations using these statistics. As an example, if we wanted to calculate the correlation coefficient between \\(X\\) and \\(Y\\), and we know that \\(R^2\\) is the correlation coefficient squared: R2&lt;-summary(my_reg)$r.squared sqrt(R2) ## [1] 0.7978255 # compare to actual correlation coefficient cor(my_df$x, my_df$y) ## [1] 0.7978255 5.2 Prediction We can use the model to make pedictions using the estimated regression model. \\[\\hat{Y}=2.090+1.974X\\] x&lt;-3 prediction&lt;-my_reg$coef[1]+my_reg$coef[2]*x prediction ## (Intercept) ## 8.227127 # multiple predictions x&lt;-c(1,3,7,10) prediction&lt;-my_reg$coef[1]+my_reg$coef[2]*x prediction ## [1] 4.346518 8.227127 15.988345 21.809259 # alternatively, we can use the predict() function and insert # a dataframe of our desired x values to predict y-hat prediction2&lt;-predict(my_reg, data.frame(x=c(1,3,7,10))) prediction2 ## 1 2 3 4 ## 4.346518 8.227127 15.988345 21.809259 5.3 Residual Plots For more, see Plotting{#04-plotting}. ggplot(data = my_df, aes(x = x, y = res))+ geom_point(color=&quot;red&quot;)+ geom_hline(yintercept=0, color=&quot;blue&quot;)+ # add horizontal line at y=0 theme_light() 5.4 Regression Output Table The broom package converts lm objects into a tidy data.frame that can easily be printed in a nice table using knitr’s kable() function for html output. # install.packages(&quot;broom&quot;) # install first if you don&#39;t have library(broom) reg2&lt;-tidy(my_reg) kable(reg2) term estimate std.error statistic p.value (Intercept) 2.406214 0.3687421 6.525466 0 x 1.940305 0.0657029 29.531510 0 stargazer(my_reg, type=&quot;html&quot;) Dependent variable: y x 1.940*** (0.066) Constant 2.406*** (0.369) Observations 500 R2 0.637 Adjusted R2 0.636 Residual Std. Error 4.152 (df = 498) F Statistic 872.110*** (df = 1; 498) Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 "],
["advanced-regression.html", "Chapter 6 Advanced Regression 6.1 Multivariate Regression 6.2 Dummy Variables 6.3 Polynomial Regression 6.4 Logarithmic Models 6.5 Standardizing Variables 6.6 Panel Data", " Chapter 6 Advanced Regression Work in Progress Most code is here, but not text explaining everything… 6.1 Multivariate Regression set.seed(1) x&lt;-rnorm(500,10,2) z&lt;-runif(500,10,20) y&lt;-rnorm(500,2*x*z,2) year&lt;-sample(seq(2000,2018,1),500,replace=TRUE) # generate categorical variables # make a shape variable shapes&lt;-c(&quot;square&quot;,&quot;circle&quot;,&quot;triangle&quot;,&quot;rectangle&quot;,&quot;trapezoid&quot;) shape&lt;-sample(shapes,500,replace=TRUE) # sample 500 random draws with replacement from shapes # make a region variable regions&lt;-c(&quot;north&quot;,&quot;south&quot;,&quot;east&quot;,&quot;west&quot;) region&lt;-sample(regions,500,replace=TRUE) # sample 500 random draws with replacement from regions # make a dummy variable yes&lt;-sample(c(0,1),500,replace=TRUE) # combine into dataframe called df df&lt;-data.frame(x=x, y=y, z=z, shape=factor(shape), region=factor(region), yes=yes, year=factor(year)) # look at new df head(df) ## x y z shape region yes year ## 1 8.747092 264.8931 15.30809 trapezoid east 0 2009 ## 2 10.367287 347.6574 16.84861 triangle west 1 2001 ## 3 8.328743 227.9193 13.83283 square east 0 2016 ## 4 13.190562 517.0824 19.54988 circle east 0 2008 ## 5 10.659016 235.8301 11.18357 trapezoid north 1 2018 ## 6 8.359063 169.6481 10.39100 trapezoid west 0 2009 It is quite simply to simply add additional covariates to a regression. In the lm object, we add variables with +. reg1&lt;-lm(y~x+z, data=df) summary(reg1) ## ## Call: ## lm(formula = y ~ x + z, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -47.969 -5.115 -0.013 5.756 42.078 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -295.7258 3.7549 -78.76 &lt;2e-16 *** ## x 29.4336 0.2671 110.19 &lt;2e-16 *** ## z 20.1389 0.1849 108.94 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 12.05 on 497 degrees of freedom ## Multiple R-squared: 0.9809, Adjusted R-squared: 0.9808 ## F-statistic: 1.277e+04 on 2 and 497 DF, p-value: &lt; 2.2e-16 6.2 Dummy Variables reg_d&lt;-lm(y~yes, data=df) summary(reg_d) ## ## Call: ## lm(formula = y ~ yes, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -199.739 -65.966 -8.196 64.445 272.577 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 296.881 5.324 55.767 &lt;2e-16 *** ## yes 2.588 7.815 0.331 0.741 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 87.15 on 498 degrees of freedom ## Multiple R-squared: 0.0002202, Adjusted R-squared: -0.001787 ## F-statistic: 0.1097 on 1 and 498 DF, p-value: 0.7406 The effect on y of going from “No” to “Yes” is 2.59. If we wanted to make a dummy variable for an existing categorical variable df$north&lt;-ifelse(region==&quot;north&quot;,1,0) df$south&lt;-ifelse(region==&quot;south&quot;,1,0) df$east&lt;-ifelse(region==&quot;east&quot;,1,0) df$west&lt;-ifelse(region==&quot;west&quot;,1,0) head(df) ## x y z shape region yes year north south east ## 1 8.747092 264.8931 15.30809 trapezoid east 0 2009 0 0 1 ## 2 10.367287 347.6574 16.84861 triangle west 1 2001 0 0 0 ## 3 8.328743 227.9193 13.83283 square east 0 2016 0 0 1 ## 4 13.190562 517.0824 19.54988 circle east 0 2008 0 0 1 ## 5 10.659016 235.8301 11.18357 trapezoid north 1 2018 1 0 0 ## 6 8.359063 169.6481 10.39100 trapezoid west 0 2009 0 0 0 ## west ## 1 0 ## 2 1 ## 3 0 ## 4 0 ## 5 0 ## 6 1 Here is where a for loop also can come in handy: for(i in unique(df$region)){ region[i]&lt;-ifelse(df$region==i,1,0) } ## Warning in region[i] &lt;- ifelse(df$region == i, 1, 0): number of items to ## replace is not a multiple of replacement length ## Warning in region[i] &lt;- ifelse(df$region == i, 1, 0): number of items to ## replace is not a multiple of replacement length ## Warning in region[i] &lt;- ifelse(df$region == i, 1, 0): number of items to ## replace is not a multiple of replacement length ## Warning in region[i] &lt;- ifelse(df$region == i, 1, 0): number of items to ## replace is not a multiple of replacement length head(df) ## x y z shape region yes year north south east ## 1 8.747092 264.8931 15.30809 trapezoid east 0 2009 0 0 1 ## 2 10.367287 347.6574 16.84861 triangle west 1 2001 0 0 0 ## 3 8.328743 227.9193 13.83283 square east 0 2016 0 0 1 ## 4 13.190562 517.0824 19.54988 circle east 0 2008 0 0 1 ## 5 10.659016 235.8301 11.18357 trapezoid north 1 2018 1 0 0 ## 6 8.359063 169.6481 10.39100 trapezoid west 0 2009 0 0 0 ## west ## 1 0 ## 2 1 ## 3 0 ## 4 0 ## 5 0 ## 6 1 6.3 Polynomial Regression x1&lt;-rnorm(500,5,1) y1&lt;-(x1-5)^2+2+rnorm(500,1,0.5) quad&lt;-data.frame(x=x1, y=y1) library(ggplot2) ggplot(quad, aes(x=x,y=y))+ geom_point()+theme_light() reg&lt;-lm(y~x, data=quad) summary(reg) ## ## Call: ## lm(formula = y ~ x, data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.3498 -0.8570 -0.3221 0.4573 12.1560 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.43961 0.34604 12.83 &lt;2e-16 *** ## x -0.08518 0.06763 -1.26 0.208 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.482 on 498 degrees of freedom ## Multiple R-squared: 0.003176, Adjusted R-squared: 0.001174 ## F-statistic: 1.586 on 1 and 498 DF, p-value: 0.2084 quadreg&lt;-lm(y~x+I(x^2), data=quad) summary(quadreg) ## ## Call: ## lm(formula = y ~ x + I(x^2), data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.51798 -0.32487 0.01175 0.33870 1.39794 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 28.22753 0.43975 64.19 &lt;2e-16 *** ## x -10.05640 0.17820 -56.43 &lt;2e-16 *** ## I(x^2) 1.00407 0.01777 56.51 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5445 on 497 degrees of freedom ## Multiple R-squared: 0.8657, Adjusted R-squared: 0.8652 ## F-statistic: 1602 on 2 and 497 DF, p-value: &lt; 2.2e-16 suppressPackageStartupMessages(library(dplyr)) quad&lt;-quad %&gt;% mutate(x2=x^2, x3=x^3) head(quad) ## x y x2 x3 ## 1 6.210004 4.668968 38.56415 239.48352 ## 2 4.247019 3.831857 18.03717 76.60422 ## 3 4.350733 3.239984 18.92888 82.35448 ## 4 4.745756 3.405515 22.52220 106.88484 ## 5 3.703630 4.782279 13.71688 50.80225 ## 6 4.575343 2.538057 20.93376 95.77914 quadreg2&lt;-lm(y~x+x2, data=quad) summary(quadreg2) ## ## Call: ## lm(formula = y ~ x + x2, data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.51798 -0.32487 0.01175 0.33870 1.39794 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 28.22753 0.43975 64.19 &lt;2e-16 *** ## x -10.05640 0.17820 -56.43 &lt;2e-16 *** ## x2 1.00407 0.01777 56.51 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5445 on 497 degrees of freedom ## Multiple R-squared: 0.8657, Adjusted R-squared: 0.8652 ## F-statistic: 1602 on 2 and 497 DF, p-value: &lt; 2.2e-16 Estimating marginal effects. marginaleffect&lt;-function(x){ quadreg$coef[2]+2*quadreg$coef[3]*x } marginaleffect(1:10) ## [1] -8.04826512 -6.04013174 -4.03199837 -2.02386500 -0.01573162 ## [6] 1.99240175 4.00053513 6.00866850 8.01680187 10.02493525 6.3.1 Higher Polynomials cubicreg&lt;-lm(y~x+x2+x3, data=quad) summary(cubicreg) ## ## Call: ## lm(formula = y ~ x + x2 + x3, data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.5223 -0.3211 0.0116 0.3374 1.3989 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 28.034692 1.102316 25.433 &lt; 2e-16 *** ## x -9.922597 0.723542 -13.714 &lt; 2e-16 *** ## x2 0.974731 0.154766 6.298 6.65e-10 *** ## x3 0.002049 0.010738 0.191 0.849 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.545 on 496 degrees of freedom ## Multiple R-squared: 0.8658, Adjusted R-squared: 0.8649 ## F-statistic: 1066 on 3 and 496 DF, p-value: &lt; 2.2e-16 cubicreg2&lt;-lm(y~x+I(x^2)+I(x^3), data=quad) summary(cubicreg2) ## ## Call: ## lm(formula = y ~ x + I(x^2) + I(x^3), data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.5223 -0.3211 0.0116 0.3374 1.3989 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 28.034692 1.102316 25.433 &lt; 2e-16 *** ## x -9.922597 0.723542 -13.714 &lt; 2e-16 *** ## I(x^2) 0.974731 0.154766 6.298 6.65e-10 *** ## I(x^3) 0.002049 0.010738 0.191 0.849 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.545 on 496 degrees of freedom ## Multiple R-squared: 0.8658, Adjusted R-squared: 0.8649 ## F-statistic: 1066 on 3 and 496 DF, p-value: &lt; 2.2e-16 cubicreg3&lt;-lm(y~poly(x,3, raw=TRUE), data=quad) summary(cubicreg3) ## ## Call: ## lm(formula = y ~ poly(x, 3, raw = TRUE), data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.5223 -0.3211 0.0116 0.3374 1.3989 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 28.034692 1.102316 25.433 &lt; 2e-16 *** ## poly(x, 3, raw = TRUE)1 -9.922597 0.723542 -13.714 &lt; 2e-16 *** ## poly(x, 3, raw = TRUE)2 0.974731 0.154766 6.298 6.65e-10 *** ## poly(x, 3, raw = TRUE)3 0.002049 0.010738 0.191 0.849 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.545 on 496 degrees of freedom ## Multiple R-squared: 0.8658, Adjusted R-squared: 0.8649 ## F-statistic: 1066 on 3 and 496 DF, p-value: &lt; 2.2e-16 Finding the maximum or minimum. min.x&lt;-(-0.5*quadreg$coef[2]/quadreg$coef[3]) min.x ## x ## 5.007834 # the predicted value of y at the minimum min.yhat&lt;-quadreg$coef[1]+quadreg$coef[2]*min.x+quadreg$coef[3]*min.x min.yhat ## (Intercept) ## -17.10504 yhat reaches a minimum of -17.11 when x is 5.01. \\(F\\)-test of nonlinearity, \\(H_0: \\beta_2=\\beta_3=0\\) library(car) ## Loading required package: carData ## ## Attaching package: &#39;car&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## recode ## The following object is masked from &#39;package:purrr&#39;: ## ## some linearHypothesis(cubicreg, c(&quot;x2&quot;,&quot;x3&quot;)) ## Linear hypothesis test ## ## Hypothesis: ## x2 = 0 ## x3 = 0 ## ## Model 1: restricted model ## Model 2: y ~ x + x2 + x3 ## ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 498 1093.99 ## 2 496 147.34 2 946.66 1593.4 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.4 Logarithmic Models quad&lt;-quad %&gt;% mutate(l.x=log(x), l.y=log(y)) head(quad) ## x y x2 x3 l.x l.y ## 1 6.210004 4.668968 38.56415 239.48352 1.826162 1.5409380 ## 2 4.247019 3.831857 18.03717 76.60422 1.446217 1.3433495 ## 3 4.350733 3.239984 18.92888 82.35448 1.470344 1.1755685 ## 4 4.745756 3.405515 22.52220 106.88484 1.557251 1.2253962 ## 5 3.703630 4.782279 13.71688 50.80225 1.309314 1.5649173 ## 6 4.575343 2.538057 20.93376 95.77914 1.520682 0.9313989 # linear log model lin_log_reg&lt;-lm(y~l.x, data = quad) summary(lin_log_reg) ## ## Call: ## lm(formula = y ~ l.x, data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.3562 -0.8767 -0.3256 0.4280 10.6428 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 6.3950 0.4952 12.914 &lt; 2e-16 *** ## l.x -1.4960 0.3082 -4.854 1.62e-06 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.451 on 498 degrees of freedom ## Multiple R-squared: 0.04518, Adjusted R-squared: 0.04326 ## F-statistic: 23.56 on 1 and 498 DF, p-value: 1.619e-06 # log-linear model log_lin_reg&lt;-lm(l.y~x, data = quad) summary(log_lin_reg) ## ## Call: ## lm(formula = l.y ~ x, data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.82126 -0.18617 -0.03703 0.16323 1.44956 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.358081 0.072125 18.829 &lt;2e-16 *** ## x -0.004126 0.014096 -0.293 0.77 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3089 on 498 degrees of freedom ## Multiple R-squared: 0.000172, Adjusted R-squared: -0.001836 ## F-statistic: 0.08567 on 1 and 498 DF, p-value: 0.7699 # log-log model log_log_reg&lt;-lm(l.y~l.x, data = quad) summary(log_log_reg) ## ## Call: ## lm(formula = l.y ~ l.x, data = quad) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.82359 -0.19326 -0.03528 0.15071 1.20178 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.68170 0.10432 16.12 &lt; 2e-16 *** ## l.x -0.21616 0.06492 -3.33 0.000934 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.3056 on 498 degrees of freedom ## Multiple R-squared: 0.02178, Adjusted R-squared: 0.01981 ## F-statistic: 11.09 on 1 and 498 DF, p-value: 0.0009342 suppressPackageStartupMessages(library(stargazer)) stargazer(lin_log_reg, log_lin_reg, log_log_reg, type=&quot;html&quot;, column.labels = c(&quot;Linear-Log&quot;, &quot;Log-Linear&quot;, &quot;Log-Log&quot;)) Dependent variable: y l.y Linear-Log Log-Linear Log-Log (1) (2) (3) l.x -1.496*** -0.216*** (0.308) (0.065) x -0.004 (0.014) Constant 6.395*** 1.358*** 1.682*** (0.495) (0.072) (0.104) Observations 500 500 500 R2 0.045 0.0002 0.022 Adjusted R2 0.043 -0.002 0.020 Residual Std. Error (df = 498) 1.451 0.309 0.306 F Statistic (df = 1; 498) 23.564*** 0.086 11.086*** Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 Interpretting the coefficients: Linear-log model: a 1% change in x yields a -149.6 units change in y Log-linear model: a 1 unit change in x yields a 0% change in y Log-log model: a 1% change in x yields a -0.22% change in y 6.5 Standardizing Variables Easiest way is to use the scale() command as part of the mutate() command in dplyr. library(gapminder) gapminder&lt;-gapminder %&gt;% mutate(s.life=scale(lifeExp), s.gdp=scale(gdpPercap), s.pop=scale(pop)) stdreg&lt;-lm(s.life~s.gdp+s.pop, data=gapminder) summary(stdreg) ## ## Call: ## lm(formula = s.life ~ s.gdp + s.pop, data = gapminder) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.4065 -0.5996 0.1591 0.6357 1.4348 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.038e-16 1.959e-02 0.00 1 ## s.gdp 5.858e-01 1.960e-02 29.89 &lt; 2e-16 *** ## s.pop 7.995e-02 1.960e-02 4.08 4.72e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.8085 on 1701 degrees of freedom ## Multiple R-squared: 0.3471, Adjusted R-squared: 0.3463 ## F-statistic: 452.2 on 2 and 1701 DF, p-value: &lt; 2.2e-16 Interpretting the coefficients: A 1 standard deviation change in gdpPercap yields a 0.59 standard deviation change in lifeExp A 1 standard deviation change in pop yields a 0.08 standard deviation change in lifeExp 6.6 Panel Data str(df) ## &#39;data.frame&#39;: 500 obs. of 11 variables: ## $ x : num 8.75 10.37 8.33 13.19 10.66 ... ## $ y : num 265 348 228 517 236 ... ## $ z : num 15.3 16.8 13.8 19.5 11.2 ... ## $ shape : Factor w/ 5 levels &quot;circle&quot;,&quot;rectangle&quot;,..: 4 5 3 1 4 4 3 1 2 4 ... ## $ region: Factor w/ 4 levels &quot;east&quot;,&quot;north&quot;,..: 1 4 1 1 2 4 3 3 1 1 ... ## $ yes : num 0 1 0 0 1 0 1 1 0 0 ... ## $ year : Factor w/ 19 levels &quot;2000&quot;,&quot;2001&quot;,..: 10 2 17 9 19 10 18 1 4 8 ... ## $ north : num 0 0 0 0 1 0 0 0 0 0 ... ## $ south : num 0 0 0 0 0 0 1 1 0 0 ... ## $ east : num 1 0 1 1 0 0 0 0 1 1 ... ## $ west : num 0 1 0 0 0 1 0 0 0 0 ... Using Least Squares Dummy Variable (LSDV) approach reg_fe&lt;-lm(y~x+region, data = df) summary(reg_fe) ## ## Call: ## lm(formula = y ~ x + region, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -133.702 -46.165 -5.717 49.537 120.099 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -9.916 14.659 -0.676 0.499 ## x 31.333 1.331 23.536 &lt;2e-16 *** ## regionnorth -11.107 8.031 -1.383 0.167 ## regionsouth -12.089 7.968 -1.517 0.130 ## regionwest -2.195 7.945 -0.276 0.782 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 60.02 on 495 degrees of freedom ## Multiple R-squared: 0.5287, Adjusted R-squared: 0.5249 ## F-statistic: 138.8 on 4 and 495 DF, p-value: &lt; 2.2e-16 De-meaned Method using plm package library(plm) ## Loading required package: Formula ## ## Attaching package: &#39;plm&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## between, lag, lead reg_fe2&lt;-plm(y~x, data = df, index = &quot;region&quot;, model = &quot;within&quot;) summary(reg_fe2) ## Oneway (individual) effect Within Model ## ## Call: ## plm(formula = y ~ x, data = df, model = &quot;within&quot;, index = &quot;region&quot;) ## ## Unbalanced Panel: n = 4, T = 98-137, N = 500 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -133.7025 -46.1652 -5.7171 49.5375 120.0992 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## x 31.3333 1.3313 23.536 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 3778400 ## Residual Sum of Squares: 1783000 ## R-Squared: 0.5281 ## Adj. R-Squared: 0.52428 ## F-statistic: 553.946 on 1 and 495 DF, p-value: &lt; 2.22e-16 6.6.1 Two Way Fixed Effects LSDV method reg_2way_fe&lt;-lm(y~x+region+year, data = df) summary(reg_2way_fe) ## ## Call: ## lm(formula = y ~ x + region + year, data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -144.498 -43.865 -3.377 49.134 127.820 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 5.271 20.281 0.260 0.795 ## x 30.875 1.356 22.775 &lt;2e-16 *** ## regionnorth -11.198 8.199 -1.366 0.173 ## regionsouth -11.487 8.156 -1.408 0.160 ## regionwest -1.072 8.096 -0.132 0.895 ## year2001 -26.478 18.142 -1.459 0.145 ## year2002 -3.579 17.490 -0.205 0.838 ## year2003 -18.924 17.587 -1.076 0.282 ## year2004 -22.182 17.521 -1.266 0.206 ## year2005 -11.986 18.819 -0.637 0.524 ## year2006 -22.034 18.293 -1.205 0.229 ## year2007 3.143 18.147 0.173 0.863 ## year2008 2.870 18.262 0.157 0.875 ## year2009 -12.448 18.742 -0.664 0.507 ## year2010 -16.316 17.583 -0.928 0.354 ## year2011 -4.261 17.522 -0.243 0.808 ## year2012 -6.719 19.379 -0.347 0.729 ## year2013 -19.188 19.911 -0.964 0.336 ## year2014 5.420 18.326 0.296 0.768 ## year2015 -14.284 19.692 -0.725 0.469 ## year2016 -11.172 17.851 -0.626 0.532 ## year2017 -7.987 18.493 -0.432 0.666 ## year2018 -19.580 17.895 -1.094 0.274 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 60.39 on 477 degrees of freedom ## Multiple R-squared: 0.5402, Adjusted R-squared: 0.519 ## F-statistic: 25.47 on 22 and 477 DF, p-value: &lt; 2.2e-16 states&lt;-c(&quot;AL&quot;,&quot;AK&quot;,&quot;AZ&quot;,&quot;AR&quot;,&quot;CA&quot;,&quot;CO&quot;,&quot;CT&quot;,&quot;DE&quot;,&quot;FL&quot;,&quot;GA&quot;,&quot;HI&quot;,&quot;ID&quot;,&quot;IL&quot;,&quot;IN&quot;,&quot;IA&quot;,&quot;KS&quot;,&quot;KY&quot;,&quot;LA&quot;,&quot;ME&quot;,&quot;MD&quot;,&quot;MA&quot;,&quot;MI&quot;,&quot;MN&quot;,&quot;MS&quot;,&quot;MO&quot;,&quot;MT&quot;,&quot;NE&quot;,&quot;NV&quot;,&quot;NH&quot;,&quot;NJ&quot;,&quot;NM&quot;,&quot;NY&quot;,&quot;NC&quot;,&quot;ND&quot;,&quot;OH&quot;,&quot;OK&quot;,&quot;OR&quot;,&quot;PA&quot;,&quot;RI&quot;,&quot;SC&quot;,&quot;SD&quot;,&quot;TN&quot;,&quot;TX&quot;,&quot;UT&quot;,&quot;VT&quot;,&quot;VA&quot;,&quot;WA&quot;,&quot;WV&quot;,&quot;WI&quot;,&quot;WY&quot;) df&lt;-data.frame() # make empty dataframe # for each state, generate data, creates dataframe called df_&quot;state&quot; e.g. df_AL, df_AK, etc. for(i in unique(states)){ assign(paste(&quot;df&quot;,i,sep=&quot;_&quot;),data.frame(state=i, year=seq(2000,2018,1), x=rnorm(19,5,1), y=rnorm(19,2*(rnorm(19,5,1)),1)) # make y approx 2*x ) } # make list of state dataframes statedfs&lt;-lapply(ls(pattern=&quot;df_&quot;),get) # combine state dataframes to df for (i in seq_along(statedfs)){ df&lt;-rbind(df,statedfs[[i]]) } # remove all individual state dataframes, (e.g. &quot;df_AL&quot;) keep only &quot;df&quot; rm(list=ls(pattern=&quot;df_&quot;)) library(&quot;plm&quot;) pdim(df, index=c(&quot;state&quot;,&quot;year&quot;)) ## Balanced Panel: n = 50, T = 19, N = 950 reg_2way_fe&lt;-lm(y~x+state+factor(year), data=df) summary(reg_2way_fe) ## ## Call: ## lm(formula = y ~ x + state + factor(year), data = df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -5.6800 -1.4700 -0.0804 1.4517 6.7585 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 11.381998 0.696423 16.344 &lt;2e-16 *** ## x -0.145891 0.073974 -1.972 0.0489 * ## stateAL -0.631120 0.714836 -0.883 0.3775 ## stateAR -1.259768 0.714804 -1.762 0.0783 . ## stateAZ -0.407688 0.714868 -0.570 0.5686 ## stateCA -0.307402 0.714781 -0.430 0.6673 ## stateCO -0.752466 0.714726 -1.053 0.2927 ## stateCT -1.308885 0.714850 -1.831 0.0674 . ## stateDE -1.278362 0.714668 -1.789 0.0740 . ## stateFL -1.474282 0.714921 -2.062 0.0395 * ## stateGA -0.884094 0.714773 -1.237 0.2165 ## stateHI -0.332327 0.714717 -0.465 0.6421 ## stateIA -0.595839 0.715165 -0.833 0.4050 ## stateID -0.547163 0.715739 -0.764 0.4448 ## stateIL -0.600631 0.714671 -0.840 0.4009 ## stateIN -0.848554 0.714770 -1.187 0.2355 ## stateKS -0.286170 0.716084 -0.400 0.6895 ## stateKY -0.741245 0.715003 -1.037 0.3002 ## stateLA -0.419623 0.715409 -0.587 0.5577 ## stateMA -0.298273 0.715053 -0.417 0.6767 ## stateMD -0.421651 0.714674 -0.590 0.5553 ## stateME -0.225449 0.714923 -0.315 0.7526 ## stateMI -0.323392 0.715337 -0.452 0.6513 ## stateMN -1.409148 0.714844 -1.971 0.0490 * ## stateMO 0.301812 0.714674 0.422 0.6729 ## stateMS -0.894070 0.716129 -1.248 0.2122 ## stateMT -0.401861 0.714677 -0.562 0.5741 ## stateNC -0.068496 0.714933 -0.096 0.9237 ## stateND -0.165348 0.715353 -0.231 0.8173 ## stateNE -0.900076 0.714719 -1.259 0.2082 ## stateNH -1.110596 0.714850 -1.554 0.1206 ## stateNJ -1.243386 0.714667 -1.740 0.0822 . ## stateNM -1.040089 0.714855 -1.455 0.1460 ## stateNV -0.617321 0.714782 -0.864 0.3880 ## stateNY -1.373121 0.715528 -1.919 0.0553 . ## stateOH -1.073487 0.714691 -1.502 0.1334 ## stateOK 0.082996 0.715137 0.116 0.9076 ## stateOR -0.076596 0.714784 -0.107 0.9147 ## statePA -1.164706 0.714974 -1.629 0.1037 ## stateRI -0.145688 0.715129 -0.204 0.8386 ## stateSC -1.228907 0.715302 -1.718 0.0861 . ## stateSD -1.082405 0.715272 -1.513 0.1306 ## stateTN -0.518475 0.715005 -0.725 0.4686 ## stateTX -0.245084 0.714922 -0.343 0.7318 ## stateUT -0.166157 0.714669 -0.232 0.8162 ## stateVA -0.851774 0.714666 -1.192 0.2336 ## stateVT -1.258232 0.714696 -1.761 0.0787 . ## stateWA -1.366209 0.716866 -1.906 0.0570 . ## stateWI -0.378345 0.716385 -0.528 0.5975 ## stateWV 0.264818 0.714670 0.371 0.7111 ## stateWY -1.193296 0.714766 -1.669 0.0954 . ## factor(year)2001 -0.639847 0.441018 -1.451 0.1472 ## factor(year)2002 -0.206312 0.440886 -0.468 0.6399 ## factor(year)2003 0.272444 0.441398 0.617 0.5372 ## factor(year)2004 0.495971 0.441746 1.123 0.2618 ## factor(year)2005 -0.351603 0.440569 -0.798 0.4250 ## factor(year)2006 0.104295 0.440831 0.237 0.8130 ## factor(year)2007 -0.181204 0.440577 -0.411 0.6810 ## factor(year)2008 -0.109937 0.441432 -0.249 0.8034 ## factor(year)2009 0.071643 0.440802 0.163 0.8709 ## factor(year)2010 0.077712 0.440860 0.176 0.8601 ## factor(year)2011 0.008026 0.440651 0.018 0.9855 ## factor(year)2012 -0.127856 0.440794 -0.290 0.7718 ## factor(year)2013 -0.067184 0.440720 -0.152 0.8789 ## factor(year)2014 -0.257845 0.440685 -0.585 0.5586 ## factor(year)2015 -0.038034 0.440549 -0.086 0.9312 ## factor(year)2016 0.096685 0.441123 0.219 0.8266 ## factor(year)2017 0.094541 0.441374 0.214 0.8304 ## factor(year)2018 -0.778523 0.441417 -1.764 0.0781 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.203 on 881 degrees of freedom ## Multiple R-squared: 0.06812, Adjusted R-squared: -0.003807 ## F-statistic: 0.9471 on 68 and 881 DF, p-value: 0.5995 reg_2way_fe2&lt;-plm(y~x, data=df, index=c(&quot;state&quot;,&quot;year&quot;), model=&quot;within&quot;, effect=&quot;twoways&quot;) summary(reg_2way_fe2) ## Twoways effects Within Model ## ## Call: ## plm(formula = y ~ x, data = df, effect = &quot;twoways&quot;, model = &quot;within&quot;, ## index = c(&quot;state&quot;, &quot;year&quot;)) ## ## Balanced Panel: n = 50, T = 19, N = 950 ## ## Residuals: ## Min. 1st Qu. Median 3rd Qu. Max. ## -5.679977 -1.470018 -0.080427 1.451664 6.758480 ## ## Coefficients: ## Estimate Std. Error t-value Pr(&gt;|t|) ## x -0.145891 0.073974 -1.9722 0.0489 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Total Sum of Squares: 4293.6 ## Residual Sum of Squares: 4274.7 ## R-Squared: 0.0043955 ## Adj. R-Squared: -0.07245 ## F-statistic: 3.88952 on 1 and 881 DF, p-value: 0.048901 "]
]
